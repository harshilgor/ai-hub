# ğŸ”„ Detailed API Request Flow

## Exact API Calls Made During Paper Fetching

### When `updatePapers()` is called:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 1: Semantic Scholar Primary Fetch                    â”‚
â”‚  Function: fetchLatestPapersFromSemanticScholar(100, 2024)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

For each of 8 AI topics (sequential, with delays):

Topic 1: "artificial intelligence"
â”œâ”€ API Call #1
â”‚  GET https://api.semanticscholar.org/graph/v1/paper/search
â”‚  Query: "artificial intelligence"
â”‚  Year: "2024,2025"
â”‚  Limit: 13 papers
â”‚  Fields: paperId,title,authors,year,abstract,citationCount...
â”‚  Headers: x-api-key: [YOUR_KEY or empty]
â”‚  â±ï¸ Wait: 200ms
â”‚
Topic 2: "machine learning"
â”œâ”€ API Call #2
â”‚  GET https://api.semanticscholar.org/graph/v1/paper/search
â”‚  Query: "machine learning"
â”‚  â±ï¸ Wait: 200ms
â”‚
Topic 3: "deep learning"
â”œâ”€ API Call #3
â”‚  â±ï¸ Wait: 200ms
â”‚
Topic 4: "neural networks"
â”œâ”€ API Call #4
â”‚  â±ï¸ Wait: 200ms
â”‚
Topic 5: "computer vision"
â”œâ”€ API Call #5
â”‚  â±ï¸ Wait: 200ms
â”‚
Topic 6: "natural language processing"
â”œâ”€ API Call #6
â”‚  â±ï¸ Wait: 200ms
â”‚
Topic 7: "large language models"
â”œâ”€ API Call #7
â”‚  â±ï¸ Wait: 200ms
â”‚
Topic 8: "reinforcement learning"
â””â”€ API Call #8
   â±ï¸ Total time: ~1.6 seconds (8 calls Ã— 200ms)

Result: ~100 papers collected
```

### If < 50 papers found, fallback to arXiv:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  STEP 2: arXiv Fallback                                      â”‚
â”‚  Function: fetchArXivPapers(50, 7)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”œâ”€ API Call #9
â”‚  GET http://export.arxiv.org/api/query
â”‚  Search: AI categories (cs.AI, cs.LG, cs.CV, etc.)
â”‚  Max Results: 50
â”‚  Days Back: 7
â”‚
â”‚  Result: 50 arXiv papers
â”‚
â””â”€ Enrich first 30 with Semantic Scholar citations:
   â”‚
   For each of 30 papers (sequential):
   â”œâ”€ API Call #10
   â”‚  GET https://api.semanticscholar.org/graph/v1/paper/arXiv:2311.12345
   â”‚  â±ï¸ Wait: 100ms
   â”‚
   â”œâ”€ API Call #11
   â”‚  GET https://api.semanticscholar.org/graph/v1/paper/arXiv:2311.12346
   â”‚  â±ï¸ Wait: 100ms
   â”‚
   â””â”€ ... (30 calls total)
      â±ï¸ Total time: ~3 seconds (30 calls Ã— 100ms)
```

---

## ğŸ“Š Total API Calls Summary

### Best Case (Semantic Scholar returns 100+ papers):
- **8 calls** to Semantic Scholar search API
- **Total time**: ~1.6 seconds
- **Rate limit impact**: 8 requests used

### Worst Case (Semantic Scholar returns < 50 papers):
- **8 calls** to Semantic Scholar search API
- **1 call** to arXiv API
- **30 calls** to Semantic Scholar paper detail API (for enrichment)
- **Total time**: ~4.6 seconds
- **Rate limit impact**: 38 requests used

---

## â±ï¸ Timing Breakdown

### Single Update Cycle:

```
0.0s  â†’ Start updatePapers()
0.1s  â†’ Call #1: "artificial intelligence"
0.3s  â†’ Call #2: "machine learning"
0.5s  â†’ Call #3: "deep learning"
0.7s  â†’ Call #4: "neural networks"
0.9s  â†’ Call #5: "computer vision"
1.1s  â†’ Call #6: "natural language processing"
1.3s  â†’ Call #7: "large language models"
1.5s  â†’ Call #8: "reinforcement learning"
1.6s  â†’ All Semantic Scholar searches complete
1.7s  â†’ Transform papers to internal format
1.8s  â†’ Remove duplicates
1.9s  â†’ Categorize by industry
2.0s  â†’ Save to cache and JSON
2.1s  â†’ Done!
```

**If fallback needed:**
```
2.0s  â†’ Check: < 50 papers? YES
2.1s  â†’ Call arXiv API
2.5s  â†’ Get 50 arXiv papers
2.6s  â†’ Start enriching with Semantic Scholar
2.7s  â†’ Enrich paper #1 (100ms wait)
2.8s  â†’ Enrich paper #2 (100ms wait)
...
5.6s  â†’ Enrich paper #30 (last one)
5.7s  â†’ Transform, deduplicate, categorize
5.8s  â†’ Save to cache and JSON
5.9s  â†’ Done!
```

---

## ğŸ”¢ Rate Limit Calculations

### Without API Key:
- **Limit**: 100 requests per 5 minutes
- **Our usage**: 8-38 requests per update
- **Updates**: Every 6 hours
- **Safety margin**: âœ… Plenty of room

### With API Key:
- **Limit**: Higher (varies by tier, typically 500-5000/5min)
- **Our usage**: 8-38 requests per update
- **Updates**: Every 6 hours
- **Safety margin**: âœ… Very safe

### Rate Limit Headroom:
```
100 requests / 5 minutes = 20 requests per minute
Our max usage: 38 requests per update
Time between updates: 6 hours = 360 minutes

Requests per hour: 38 / 6 = ~6.3 requests/hour
Requests per 5 minutes: 6.3 / 12 = ~0.5 requests/5min

âœ… We use < 1% of rate limit capacity!
```

---

## ğŸ¯ Real-World Example

### What happens when you click "Refresh":

```
User clicks "Refresh" button
    â†“
Frontend: POST /api/papers/refresh
    â†“
Backend: updatePapers() starts (background)
    â†“
Console logs:
  "ğŸ”„ Fetching new papers..."
  "ğŸ” Fetching from Semantic Scholar..."
    â†“
8 API calls to Semantic Scholar (with 200ms delays)
    â†“
Console logs:
  "âœ… Found 100 papers from Semantic Scholar"
    â†“
Transform papers
    â†“
Console logs:
  "ğŸ“ Removed 15 duplicates"
    â†“
Categorize by industry
    â†“
Save to database
    â†“
Console logs:
  "âœ… Updated 85 papers"
  "ğŸ“Š Industry stats: { 'Machine Learning': 25, ... }"
    â†“
Frontend polls /api/papers and sees new papers!
```

---

## ğŸ” Monitoring API Usage

### Check how many requests you've made:

The backend doesn't track this automatically, but you can:

1. **Check Semantic Scholar dashboard** (if you have API key)
2. **Monitor backend logs** for API errors
3. **Add custom logging**:

```javascript
// In semanticScholarService.js
let requestCount = 0;

// Before each API call:
requestCount++;
console.log(`ğŸ“¡ API Request #${requestCount} to Semantic Scholar`);
```

---

## ğŸš¨ Error Handling

### What happens if API fails?

1. **Semantic Scholar search fails for one topic:**
   - âœ… Continues with other topics
   - âœ… Logs error but doesn't stop

2. **All Semantic Scholar searches fail:**
   - âœ… Falls back to arXiv
   - âœ… Still gets papers (just without citations)

3. **Rate limit exceeded:**
   - âŒ API returns 429 error
   - âœ… Code catches error, logs it
   - âœ… Returns empty array, falls back to arXiv

4. **Network timeout:**
   - âœ… 30-second default timeout
   - âœ… Catches error, continues with other sources

---

## ğŸ’¡ Optimization Opportunities

### Current approach is safe but could be faster:

1. **Parallel requests** (instead of sequential):
   - Could make all 8 searches at once
   - âš ï¸ But might hit rate limits faster

2. **Batch API for enrichment**:
   - Instead of 30 individual calls, use batch API
   - âœ… Already implemented in `fetchPapersBatch()`
   - Could be used for arXiv enrichment

3. **Caching strategy**:
   - Cache individual paper details
   - Avoid re-fetching same papers

---

## ğŸ“ Summary

**Total API calls per update:**
- Minimum: 8 (Semantic Scholar only)
- Maximum: 39 (Semantic Scholar + arXiv + enrichment)

**Total time per update:**
- Minimum: ~2 seconds
- Maximum: ~6 seconds

**Update frequency:**
- Automatic: Every 6 hours
- Manual: On-demand via refresh button

**Rate limit safety:**
- âœ… Very safe (uses < 1% of free tier limit)

